{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3572572",
   "metadata": {},
   "source": [
    "Version 5 of reproduction of the following paper : Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
    "\n",
    "What is added from V4 : \n",
    "- Based on LLMware, but applied to TriviaQA --> application to something else so that the learning sticks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9a638",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97de868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from llmware.library import Library\n",
    "from llmware.retrieval import Query\n",
    "from llmware.setup import Setup\n",
    "from llmware.status import Status\n",
    "from llmware.models import ModelCatalog\n",
    "from llmware.configs import LLMWareConfig, MilvusConfig\n",
    "\n",
    "import time\n",
    "from llmware.prompts import Prompt, HumanInTheLoop\n",
    "from llmware.models import ModelCatalog\n",
    "\n",
    "from importlib import util\n",
    "\n",
    "from datasets import Dataset, load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591db95",
   "metadata": {},
   "source": [
    "LIBRARY : import documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e2bffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': Value('string'),\n",
       " 'question_id': Value('string'),\n",
       " 'question_source': Value('string'),\n",
       " 'entity_pages': {'doc_source': List(Value('string')),\n",
       "  'filename': List(Value('string')),\n",
       "  'title': List(Value('string')),\n",
       "  'wiki_context': List(Value('string'))},\n",
       " 'search_results': {'description': List(Value('string')),\n",
       "  'filename': List(Value('string')),\n",
       "  'rank': List(Value('int32')),\n",
       "  'title': List(Value('string')),\n",
       "  'url': List(Value('string')),\n",
       "  'search_context': List(Value('string'))},\n",
       " 'answer': {'aliases': List(Value('string')),\n",
       "  'normalized_aliases': List(Value('string')),\n",
       "  'matched_wiki_entity_name': Value('string'),\n",
       "  'normalized_matched_wiki_entity_name': Value('string'),\n",
       "  'normalized_value': Value('string'),\n",
       "  'type': Value('string'),\n",
       "  'value': Value('string')}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORT TRIVIAQA dataset\n",
    "\n",
    "# Load TriviaQA (unfiltered for simplicity)\n",
    "dataset = load_dataset(\"trivia_qa\", \"unfiltered\")\n",
    "\n",
    "# Take first 50 examples for quick testing\n",
    "test_set = dataset[\"train\"].select(range(50))\n",
    "\n",
    "# List of the features of the dataset\n",
    "features = dataset[\"train\"].features; features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c04142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 1998 was the Chinese year of which creature?\n",
      "Answer: Tiger\n"
     ]
    }
   ],
   "source": [
    "#PRINT ONE QUESTION AND ANSWER\n",
    "digit = 77\n",
    "example = dataset[\"train\"][digit]\n",
    "\n",
    "# Print the question and its answer\n",
    "print(\"Question:\", example[\"question\"])\n",
    "print(\"Answer:\", example[\"answer\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7637a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION THAT WILL CREATE A LIBRARY\n",
    "\n",
    "def create_library(library_name):\n",
    "\n",
    "    print (f\"\\n > Creating library '{library_name}'...\")\n",
    "\n",
    "    library = Library().create_new_library(library_name)\n",
    "\n",
    "    return library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd04af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > Creating library 'RAG_V5_Lib'...\n"
     ]
    }
   ],
   "source": [
    "# CREATE LIBRARY\n",
    "\n",
    "library_name = \"RAG_V5_Lib\"\n",
    "library = create_library(library_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f159b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO PARSE THE TRIVIAQA DATASET AND ADD THEM TO THE LIBRARY\n",
    "\n",
    "def dataset_to_file(dataset):\n",
    "    print(\"\\n > Transferring dataset to file ...\")\n",
    "\n",
    "    # Extract text from dataset (e.g., questions and answers)\n",
    "    texts = []\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(\"Data\", exist_ok=True)\n",
    "\n",
    "\n",
    "    for i in range(len(dataset[\"train\"][1:10])):  # Limiting to first 10 for demonstration\n",
    "        question = dataset[\"train\"][\"question\"][i]\n",
    "        answer = dataset[\"train\"][\"answer\"][i]\n",
    "        combined_text = f\"Q: {question}\\nA: {answer}\"\n",
    "        #texts.append(combined_text)\n",
    "\n",
    "        # Define the full path to the file\n",
    "        file_path = os.path.join(\"Data\", f\"TriviaQA_{i}.txt\")\n",
    "\n",
    "        # Write the combined text to a file\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(combined_text)\n",
    "            print(f\"File saved as {file_path}\")\n",
    "\n",
    "def parse_files(library, data_path):\n",
    "    print (f\"\\n > Parsing and adding dataset to library ...\")\n",
    "    library.add_files(input_folder_path=data_path, chunk_size=400, max_chunk_size=800, smart_chunking=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a507eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > Transferring dataset to file ...\n",
      "File saved as Data\\TriviaQA_0.txt\n",
      "File saved as Data\\TriviaQA_1.txt\n",
      "File saved as Data\\TriviaQA_2.txt\n",
      "File saved as Data\\TriviaQA_3.txt\n",
      "File saved as Data\\TriviaQA_4.txt\n",
      "File saved as Data\\TriviaQA_5.txt\n",
      "\n",
      " > Parsing and adding dataset to library ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mINFO: update:  Duplicate files (skipped): 6\u001b[39m\n",
      "\u001b[37mINFO: update:  Total uploaded: 0\u001b[39m\n"
     ]
    }
   ],
   "source": [
    " #APPLY THE FUNCTION\n",
    "dataset_to_file(dataset)\n",
    "parse_files(library, \"Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56999a",
   "metadata": {},
   "source": [
    "RETRIEVER EMBEDDINGS : Turn text into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55578ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO MAKE EMBEDDINGS\n",
    "\n",
    "def make_embeddings(embedding_model_name, vector_db):\n",
    "    print(\"Generating Embeddings in {} db - with Model- {}\".format(vector_db, embedding_model_name))\n",
    "    LLMWareConfig().set_active_db(\"sqlite\")\n",
    "    MilvusConfig().set_config(\"lite\", True)\n",
    "    LLMWareConfig().set_vector_db(vector_db)\n",
    "    library.install_new_embedding(embedding_model_name=embedding_model_name, vector_db=vector_db, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8bfa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all-MiniLM-L6-v2',\n",
       " 'all-mpnet-base-v2',\n",
       " 'industry-bert-insurance',\n",
       " 'industry-bert-contracts',\n",
       " 'industry-bert-asset-management',\n",
       " 'industry-bert-sec',\n",
       " 'industry-bert-loans',\n",
       " 'nomic-ai/nomic-embed-text-v1',\n",
       " 'jinaai/jina-embeddings-v2-base-en',\n",
       " 'jinaai/jina-embeddings-v2-small-en',\n",
       " 'BAAI/bge-small-en-v1.5',\n",
       " 'BAAI/bge-large-en-v1.5',\n",
       " 'BAAI/bge-base-en-v1.5',\n",
       " 'thenlper/gte-small',\n",
       " 'thenlper/gte-base',\n",
       " 'thenlper/gte-large',\n",
       " 'llmrails/ember-v1',\n",
       " 'WhereIsAI/UAE-Large-V1',\n",
       " 'text-embedding-ada-002',\n",
       " 'text-embedding-3-small',\n",
       " 'text-embedding-3-large',\n",
       " 'medium',\n",
       " 'xlarge',\n",
       " 'embed-english-v3.0',\n",
       " 'embed-multilingual-v3.0',\n",
       " 'embed-english-light-v3.0',\n",
       " 'embed-multilingual-light-v3.0',\n",
       " 'embed-english-v2.0',\n",
       " 'embed-english-light-v2.0',\n",
       " 'embed-multilingual-v2.0',\n",
       " 'textembedding-gecko@latest']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIST OF THE EMBEDDING MODELS AVAILABLE\n",
    "embedding_models = ModelCatalog().list_embedding_models()\n",
    "model_names = [model['model_name'] for model in embedding_models]; model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794142a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Embeddings in faiss db - with Model- mini-lm-sbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mINFO: update: EmbeddingHandler - FAISS - embedding_summary - {'embeddings_created': 0, 'embedded_blocks': 22, 'embedding_dims': 384, 'time_stamp': '2025-11-12_210755'}\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# MAKE EMBEDDINGS\n",
    "embedding_model_name = \"mini-lm-sbert\"\n",
    "vector_db = \"faiss\"\n",
    "make_embeddings(embedding_model_name, vector_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6310cf4",
   "metadata": {},
   "source": [
    "GENERATOR : PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78184b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(llm_model_name, digit):\n",
    "    print(\"Loading model for LLM inference -\", llm_model_name)\n",
    "    query = dataset[\"train\"][digit][\"question\"]\n",
    "    prompter = Prompt().load_model(llm_model_name, temperature=0.0, sample=False)\n",
    "    results = Query(library).semantic_query(query, result_count=80, embedding_distance_threshold=1.0)\n",
    "\n",
    "    # iterate files in Data folder\n",
    "    for idx, contract in enumerate(sorted(os.listdir(\"Data\"))):\n",
    "        if contract == \".DS_Store\":\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nContract {idx}: {contract}\")\n",
    "        qr = []\n",
    "\n",
    "        # collect top retrievals that come from this contract\n",
    "        for entry in results:\n",
    "            library_fn = entry.get(\"file_source\", \"\")\n",
    "            # normalize file name split on os.sep to be robust\n",
    "            if os.sep in library_fn:\n",
    "                library_fn = library_fn.split(os.sep)[-1]\n",
    "            if library_fn == contract:\n",
    "                qr.append(entry)\n",
    "\n",
    "        print(f\"  - Retrieved {len(qr)} items for file {contract}\")\n",
    "\n",
    "        # skip if nothing was retrieved for this contract\n",
    "        if not qr:\n",
    "            print(f\"  -> No retrievals for {contract}, skipping LLM call.\")\n",
    "            continue\n",
    "\n",
    "        # add the query results as source/context to the prompter\n",
    "        prompter.add_source_query_results(query_results=qr)\n",
    "\n",
    "        # call the model (may return multiple call dicts)\n",
    "        try:\n",
    "            responses = prompter.prompt_with_source(query, prompt_name=\"default_with_context\")\n",
    "        except Exception as e:\n",
    "            print(f\"  !! LLM call failed for {contract}: {e}\")\n",
    "            prompter.clear_source_materials()\n",
    "            continue\n",
    "\n",
    "        # responses is a list of dicts; combine all llm_response parts into one string\n",
    "        llm_text_parts = []\n",
    "        for r in responses:\n",
    "            # adapt to actual key names if different\n",
    "            llm_resp = r.get(\"llm_response\") or r.get(\"response\") or r.get(\"text\") or \"\"\n",
    "            llm_text_parts.append(llm_resp.strip())\n",
    "\n",
    "        llm_text = \"\\n\\n\".join([p for p in llm_text_parts if p])\n",
    "\n",
    "        # get ground-truth answer (robust to different shapes)\n",
    "        answer_obj = dataset[\"train\"][digit].get(\"answer\")\n",
    "        if isinstance(answer_obj, dict):\n",
    "            answer_val = answer_obj.get(\"value\", \"\")\n",
    "        else:\n",
    "            answer_val = answer_obj\n",
    "\n",
    "        # if answer_val is a list, join it; else leave as string\n",
    "        if isinstance(answer_val, (list, tuple)):\n",
    "            answer_text = \" ||| \".join(map(str, answer_val))\n",
    "        else:\n",
    "            answer_text = str(answer_val)\n",
    "\n",
    "        # Print the LLM answer and ground truth\n",
    "        print(f\"\\n  LLM answer (file {contract}):\\n{llm_text}\\n\")\n",
    "        print(f\"  Ground-truth answer:\\n{answer_text}\\n\")\n",
    "\n",
    "        # start fresh for next document\n",
    "        prompter.clear_source_materials()\n",
    "\n",
    "        # Save jsonl report with full transaction history to /prompt_history folder\n",
    "        print(\"\\nupdate: Prompt state saved at: \", os.path.join(LLMWareConfig.get_prompt_path(),prompter.prompt_id))\n",
    "\n",
    "        prompter.save_state()\n",
    "\n",
    "        # Generate CSV report for easy Human review in Excel\n",
    "        csv_output = HumanInTheLoop(prompter).export_current_interaction_to_csv()\n",
    "\n",
    "        print(\"\\nupdate: CSV output for human review - \", csv_output)\n",
    "\n",
    "    print(\"\\nGenerator completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6747375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meta-Llama-3-8B',\n",
       " 'Meta-Llama-3-8B-Instruct',\n",
       " 'QuantFactory/Meta-Llama-3-8B-GGUF',\n",
       " 'QuantFactory/Meta-Llama-3-8B-Instruct-GGUF',\n",
       " 'TheBloke/Llama-2-7B-Chat-GGUF',\n",
       " 'TheBloke/OpenHermes-2.5-Mistral-7B-GGUF',\n",
       " 'TheBloke/Starling-LM-7B-alpha-GGUF',\n",
       " 'TheBloke/zephyr-7B-beta-GGUF',\n",
       " 'bartowski/Meta-Llama-3-8B-Instruct-GGUF',\n",
       " 'bling-answer-tool',\n",
       " 'bling-phi-2-gguf',\n",
       " 'bling-phi-3-gguf',\n",
       " 'bling-phi-3-onnx',\n",
       " 'bling-phi-3-ov',\n",
       " 'bling-phi-3.5-gguf',\n",
       " 'bling-qwen-0.5b-gguf',\n",
       " 'bling-qwen-1.5b-gguf',\n",
       " 'bling-qwen-1.5b-ov',\n",
       " 'bling-qwen-500m-ov',\n",
       " 'bling-stablelm-3b-tool',\n",
       " 'bling-tiny-llama-onnx',\n",
       " 'bling-tiny-llama-ov',\n",
       " 'chat-bison@001',\n",
       " 'claude-2.0',\n",
       " 'claude-2.1',\n",
       " 'claude-3-5-haiku-20241022',\n",
       " 'claude-3-5-sonnet-20240620',\n",
       " 'claude-3-7-sonnet-20250219',\n",
       " 'claude-3-haiku-20240307',\n",
       " 'claude-3-opus-20240229',\n",
       " 'claude-3-sonnet-20240229',\n",
       " 'claude-instant-v1',\n",
       " 'claude-v1',\n",
       " 'codegemma-7b-it-ov',\n",
       " 'command-medium-nightly',\n",
       " 'command-xlarge-nightly',\n",
       " 'deepseek-qwen-14b-gguf',\n",
       " 'deepseek-qwen-7b-gguf',\n",
       " 'dolphin-2.9.3-mistral-7b-32k-ov',\n",
       " 'dolphin-2.9.4-llama3.1-8b-ov',\n",
       " 'dragon-llama-3.1-gguf',\n",
       " 'dragon-llama-answer-tool',\n",
       " 'dragon-llama2-ov',\n",
       " 'dragon-mistral-0.3-gguf',\n",
       " 'dragon-mistral-0.3-onnx',\n",
       " 'dragon-mistral-0.3-ov',\n",
       " 'dragon-mistral-answer-tool',\n",
       " 'dragon-mistral-ov',\n",
       " 'dragon-qwen-7b-gguf',\n",
       " 'dragon-qwen-7b-ov',\n",
       " 'dragon-yi-6b-ov',\n",
       " 'dragon-yi-9b-gguf',\n",
       " 'dragon-yi-9b-ov',\n",
       " 'dragon-yi-9b-ov',\n",
       " 'dragon-yi-answer-tool',\n",
       " 'dreamgen-wizardlm-2-7b-ov',\n",
       " 'gemini-1.5-pro',\n",
       " 'gemma-2-27b-instruct-gguf',\n",
       " 'gemma-2-9b-instruct-gguf',\n",
       " 'gemma-2b-it-onnx',\n",
       " 'gemma-2b-it-ov',\n",
       " 'gemma-7b-it-ov',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'gpt-4',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-4-1106-preview',\n",
       " 'gpt-4o',\n",
       " 'gpt-4o-2024-05-13',\n",
       " 'gpt-4o-2024-08-06',\n",
       " 'gpt-4o-mini',\n",
       " 'gpt-4o-mini-2024-07-18',\n",
       " 'intel-neural-chat-7b-v3-2-ov',\n",
       " 'j2-grande-instruct',\n",
       " 'j2-jumbo-instruct',\n",
       " 'llama-2-13b-chat-ov',\n",
       " 'llama-2-chat-onnx',\n",
       " 'llama-2-chat-ov',\n",
       " 'llama-3.1-instruct-gguf',\n",
       " 'llama-3.1-instruct-onnx',\n",
       " 'llama-3.1-instruct-ov',\n",
       " 'llama-3.2-1b-instruct-gguf',\n",
       " 'llama-3.2-1b-instruct-onnx',\n",
       " 'llama-3.2-1b-instruct-ov',\n",
       " 'llama-3.2-3b-instruct-gguf',\n",
       " 'llama-3.2-3b-instruct-onnx',\n",
       " 'llama-3.2-3b-instruct-ov',\n",
       " 'llama-3.2-3b-onnx-qnn',\n",
       " 'llmware-inference-server',\n",
       " 'llmware/bling-1.4b-0.1',\n",
       " 'llmware/bling-1b-0.1',\n",
       " 'llmware/bling-cerebras-1.3b-0.1',\n",
       " 'llmware/bling-falcon-1b-0.1',\n",
       " 'llmware/bling-phi-3',\n",
       " 'llmware/bling-phi-3.5',\n",
       " 'llmware/bling-red-pajamas-3b-0.1',\n",
       " 'llmware/bling-sheared-llama-1.3b-0.1',\n",
       " 'llmware/bling-sheared-llama-2.7b-0.1',\n",
       " 'llmware/bling-stable-lm-3b-4e1t-v0',\n",
       " 'llmware/bling-tiny-llama-v0',\n",
       " 'llmware/dragon-deci-6b-v0',\n",
       " 'llmware/dragon-deci-7b-v0',\n",
       " 'llmware/dragon-falcon-7b-v0',\n",
       " 'llmware/dragon-llama-3.1',\n",
       " 'llmware/dragon-llama-7b-gguf',\n",
       " 'llmware/dragon-llama-7b-v0',\n",
       " 'llmware/dragon-mistral-0.3',\n",
       " 'llmware/dragon-mistral-7b-gguf',\n",
       " 'llmware/dragon-mistral-7b-v0',\n",
       " 'llmware/dragon-qwen-7b',\n",
       " 'llmware/dragon-red-pajama-7b-v0',\n",
       " 'llmware/dragon-stablelm-7b-v0',\n",
       " 'llmware/dragon-yi-6b-gguf',\n",
       " 'llmware/dragon-yi-6b-v0',\n",
       " 'llmware/slim-category',\n",
       " 'llmware/slim-emotions',\n",
       " 'llmware/slim-extract-tiny-tool',\n",
       " 'llmware/slim-intent',\n",
       " 'llmware/slim-ner',\n",
       " 'llmware/slim-nli',\n",
       " 'llmware/slim-q-gen-phi-3',\n",
       " 'llmware/slim-q-gen-tiny',\n",
       " 'llmware/slim-qa-gen-phi-3',\n",
       " 'llmware/slim-qa-gen-tiny',\n",
       " 'llmware/slim-ratings',\n",
       " 'llmware/slim-sentiment',\n",
       " 'llmware/slim-sql-1b-v0',\n",
       " 'llmware/slim-summary-tiny-tool',\n",
       " 'llmware/slim-tags',\n",
       " 'llmware/slim-topics',\n",
       " 'mathstral-7b-ov',\n",
       " 'microsoft/Phi-3-mini-128k-instruct',\n",
       " 'microsoft/Phi-3-mini-4k-instruct',\n",
       " 'microsoft/Phi-3-mini-4k-instruct-gguf',\n",
       " 'mistral-7b-instruct-v0.2-ov',\n",
       " 'mistral-7b-instruct-v0.3-gguf',\n",
       " 'mistral-7b-instruct-v0.3-onnx',\n",
       " 'mistral-7b-instruct-v0.3-ov',\n",
       " 'mistral-7b-instruct-v0.3-ov',\n",
       " 'mistral-nemo-instruct-2407-ov',\n",
       " 'mistral-small-instruct-2409-ov',\n",
       " 'nvidia-llama3-chatqa-1.5-8b-ov',\n",
       " 'o1',\n",
       " 'o1-pro',\n",
       " 'o3-mini',\n",
       " 'openchat-3.6-8b-20240522-ov',\n",
       " 'phi-3-onnx',\n",
       " 'phi-3-onnx',\n",
       " 'phi-3-ov',\n",
       " 'phi-3.5-gguf',\n",
       " 'phi-4-gguf',\n",
       " 'phi-4-mini-gguf',\n",
       " 'qwen-2.5-14b-instruct-gguf',\n",
       " 'qwen-2.5-7b-coder-gguf',\n",
       " 'qwen2-0.5b-chat-ov',\n",
       " 'qwen2-0.5b-instruct-gguf',\n",
       " 'qwen2-0.5b-instruct-gguf',\n",
       " 'qwen2-1.5b-instruct-gguf',\n",
       " 'qwen2-1.5b-instruct-gguf',\n",
       " 'qwen2-1.5b-instruct-ov',\n",
       " 'qwen2-7B-instruct-gguf',\n",
       " 'qwen2-7B-instruct-gguf',\n",
       " 'qwen2-7b-instruct-ov',\n",
       " 'qwen2.5-0.5b-instruct-ov',\n",
       " 'qwen2.5-0.5b-instruct-ov',\n",
       " 'qwen2.5-1.5b-instruct-ov',\n",
       " 'qwen2.5-14b-instruct-ov',\n",
       " 'qwen2.5-32b-gguf',\n",
       " 'qwen2.5-3b-instruct-ov',\n",
       " 'qwen2.5-3b-instruct-ov',\n",
       " 'qwen2.5-7b-instruct-ov',\n",
       " 'qwen2.5-coder-7b-instruct-ov',\n",
       " 'slim-boolean',\n",
       " 'slim-boolean-phi-3-gguf',\n",
       " 'slim-boolean-phi-3-onnx',\n",
       " 'slim-boolean-phi-3-ov',\n",
       " 'slim-boolean-tool',\n",
       " 'slim-category-tool',\n",
       " 'slim-emotions-onnx',\n",
       " 'slim-emotions-ov',\n",
       " 'slim-emotions-tool',\n",
       " 'slim-extract',\n",
       " 'slim-extract-phi-3-gguf',\n",
       " 'slim-extract-phi-3-onnx',\n",
       " 'slim-extract-phi-3-ov',\n",
       " 'slim-extract-qwen-0.5b-ov',\n",
       " 'slim-extract-qwen-1.5b-gguf',\n",
       " 'slim-extract-qwen-1.5b-ov',\n",
       " 'slim-extract-qwen-nano-gguf',\n",
       " 'slim-extract-tiny',\n",
       " 'slim-extract-tiny-onnx',\n",
       " 'slim-extract-tiny-ov',\n",
       " 'slim-extract-tool',\n",
       " 'slim-intent-onnx',\n",
       " 'slim-intent-ov',\n",
       " 'slim-intent-tool',\n",
       " 'slim-ner-onnx',\n",
       " 'slim-ner-ov',\n",
       " 'slim-ner-tool',\n",
       " 'slim-nli-tool',\n",
       " 'slim-q-gen-phi-3-tool',\n",
       " 'slim-q-gen-tiny-ov',\n",
       " 'slim-q-gen-tiny-tool',\n",
       " 'slim-qa-gen-phi-3-tool',\n",
       " 'slim-qa-gen-tiny-ov',\n",
       " 'slim-qa-gen-tiny-tool',\n",
       " 'slim-ratings-onnx',\n",
       " 'slim-ratings-ov',\n",
       " 'slim-ratings-tool',\n",
       " 'slim-sa-ner',\n",
       " 'slim-sa-ner-phi-3-gguf',\n",
       " 'slim-sa-ner-phi-3-ov',\n",
       " 'slim-sa-ner-tool',\n",
       " 'slim-sentiment-onnx',\n",
       " 'slim-sentiment-ov',\n",
       " 'slim-sentiment-tool',\n",
       " 'slim-sql-onnx',\n",
       " 'slim-sql-ov',\n",
       " 'slim-sql-tool',\n",
       " 'slim-summary',\n",
       " 'slim-summary-phi-3-gguf',\n",
       " 'slim-summary-phi-3-onnx',\n",
       " 'slim-summary-phi-3-ov',\n",
       " 'slim-summary-tiny',\n",
       " 'slim-summary-tiny-onnx',\n",
       " 'slim-summary-tiny-ov',\n",
       " 'slim-summary-tool',\n",
       " 'slim-tags-3b',\n",
       " 'slim-tags-3b-tool',\n",
       " 'slim-tags-onnx',\n",
       " 'slim-tags-ov',\n",
       " 'slim-tags-tool',\n",
       " 'slim-topics-onnx',\n",
       " 'slim-topics-ov',\n",
       " 'slim-topics-tool',\n",
       " 'slim-xsum',\n",
       " 'slim-xsum-phi-3-gguf',\n",
       " 'slim-xsum-phi-3-ov',\n",
       " 'slim-xsum-tool',\n",
       " 'stablelm-2-zephyr-1_6b-ov',\n",
       " 'stablelm-zephyr-3b-ov',\n",
       " 'summarize-medium',\n",
       " 'summarize-xlarge',\n",
       " 'teknium-open-hermes-2.5-mistral-ov',\n",
       " 'text-ada-001',\n",
       " 'text-babbage-001',\n",
       " 'text-bison@001',\n",
       " 'text-curie-001',\n",
       " 'text-davinci-003',\n",
       " 'tiny-dolphin-2.8-1.1b-ov',\n",
       " 'tiny-llama-chat-gguf',\n",
       " 'tiny-llama-chat-onnx',\n",
       " 'tiny-llama-chat-ov',\n",
       " 'whisper-cpp-base',\n",
       " 'whisper-cpp-base-english',\n",
       " 'whisper-cpp-tiny-diarize',\n",
       " 'yi-6b-1.5v-chat-ov',\n",
       " 'yi-9b-chat-ov',\n",
       " 'zephyr-mistral-7b-chat-ov']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# LIST OF THE EMBEDDING MODELS AVAILABLE\n",
    "generative_models = ModelCatalog().list_generative_models()\n",
    "gen_model_names = [model['model_name'] for model in generative_models]; gen_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "858b4467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for LLM inference - bling-phi-3-gguf\n",
      "\n",
      "Contract 0: TriviaQA_0.txt\n",
      "  - Retrieved 2 items for file TriviaQA_0.txt\n",
      "\n",
      "  LLM answer (file TriviaQA_0.txt):\n",
      "Not Found.\n",
      "\n",
      "  Ground-truth answer:\n",
      "Sinclair Lewis\n",
      "\n",
      "\n",
      "update: Prompt state saved at:  C:\\Users\\xavie\\llmware_data\\prompt_history\\093e6a50-e0d6-490b-83e3-dcf6a27971bc\n",
      "\n",
      "update: CSV output for human review -  {'report_name': 'interaction_report_2025-11-12_211247.csv', 'report_fp': 'C:\\\\Users\\\\xavie\\\\llmware_data\\\\prompt_history\\\\interaction_report_2025-11-12_211247.csv', 'results': 1}\n",
      "\n",
      "Contract 1: TriviaQA_1.txt\n",
      "  - Retrieved 1 items for file TriviaQA_1.txt\n",
      "\n",
      "  LLM answer (file TriviaQA_1.txt):\n",
      "Sinclair Lewis\n",
      "\n",
      "  Ground-truth answer:\n",
      "Sinclair Lewis\n",
      "\n",
      "\n",
      "update: Prompt state saved at:  C:\\Users\\xavie\\llmware_data\\prompt_history\\093e6a50-e0d6-490b-83e3-dcf6a27971bc\n",
      "\n",
      "update: CSV output for human review -  {'report_name': 'interaction_report_2025-11-12_211300.csv', 'report_fp': 'C:\\\\Users\\\\xavie\\\\llmware_data\\\\prompt_history\\\\interaction_report_2025-11-12_211300.csv', 'results': 2}\n",
      "\n",
      "Contract 2: TriviaQA_2.txt\n",
      "  - Retrieved 1 items for file TriviaQA_2.txt\n",
      "\n",
      "  LLM answer (file TriviaQA_2.txt):\n",
      "Not Found.\n",
      "\n",
      "  Ground-truth answer:\n",
      "Sinclair Lewis\n",
      "\n",
      "\n",
      "update: Prompt state saved at:  C:\\Users\\xavie\\llmware_data\\prompt_history\\093e6a50-e0d6-490b-83e3-dcf6a27971bc\n",
      "\n",
      "update: CSV output for human review -  {'report_name': 'interaction_report_2025-11-12_211324.csv', 'report_fp': 'C:\\\\Users\\\\xavie\\\\llmware_data\\\\prompt_history\\\\interaction_report_2025-11-12_211324.csv', 'results': 3}\n",
      "\n",
      "Contract 3: TriviaQA_3.txt\n",
      "  - Retrieved 1 items for file TriviaQA_3.txt\n",
      "\n",
      "  LLM answer (file TriviaQA_3.txt):\n",
      "Not Found.\n",
      "\n",
      "  Ground-truth answer:\n",
      "Sinclair Lewis\n",
      "\n",
      "\n",
      "update: Prompt state saved at:  C:\\Users\\xavie\\llmware_data\\prompt_history\\093e6a50-e0d6-490b-83e3-dcf6a27971bc\n",
      "\n",
      "update: CSV output for human review -  {'report_name': 'interaction_report_2025-11-12_211333.csv', 'report_fp': 'C:\\\\Users\\\\xavie\\\\llmware_data\\\\prompt_history\\\\interaction_report_2025-11-12_211333.csv', 'results': 4}\n",
      "\n",
      "Contract 4: TriviaQA_4.txt\n",
      "  - Retrieved 1 items for file TriviaQA_4.txt\n",
      "\n",
      "  LLM answer (file TriviaQA_4.txt):\n",
      "Not Found.\n",
      "\n",
      "  Ground-truth answer:\n",
      "Sinclair Lewis\n",
      "\n",
      "\n",
      "update: Prompt state saved at:  C:\\Users\\xavie\\llmware_data\\prompt_history\\093e6a50-e0d6-490b-83e3-dcf6a27971bc\n",
      "\n",
      "update: CSV output for human review -  {'report_name': 'interaction_report_2025-11-12_211343.csv', 'report_fp': 'C:\\\\Users\\\\xavie\\\\llmware_data\\\\prompt_history\\\\interaction_report_2025-11-12_211343.csv', 'results': 5}\n",
      "\n",
      "Contract 5: TriviaQA_5.txt\n",
      "  - Retrieved 1 items for file TriviaQA_5.txt\n",
      "\n",
      "  LLM answer (file TriviaQA_5.txt):\n",
      "Not Found.\n",
      "\n",
      "  Ground-truth answer:\n",
      "Sinclair Lewis\n",
      "\n",
      "\n",
      "update: Prompt state saved at:  C:\\Users\\xavie\\llmware_data\\prompt_history\\093e6a50-e0d6-490b-83e3-dcf6a27971bc\n",
      "\n",
      "update: CSV output for human review -  {'report_name': 'interaction_report_2025-11-12_211352.csv', 'report_fp': 'C:\\\\Users\\\\xavie\\\\llmware_data\\\\prompt_history\\\\interaction_report_2025-11-12_211352.csv', 'results': 6}\n",
      "\n",
      "Generator completed.\n"
     ]
    }
   ],
   "source": [
    "llm_model_name = \"bling-phi-3-gguf\"\n",
    "generator(llm_model_name, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a6eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
